
\chapter{Introduction}
\label{chap:intr}

\section*{Historical context}
While mankind has been fascinated by the human mind for a long time, only the last 70 years of rapid technological advances finally allowed us to peer deep into the human brain.
New recordings techniques, theoretical models, and detailed simulations facilitated by the increase in computational power have opened new horizons in the field of neuroscience.
But to this day, a lot remains unclear about how the activity of billions of neural cells interconnected through a dense web of dynamic circuits translates into complex processes such as perception, movement, reasoning or learning.  \\

One of the recent subfields, namely \textit{computational neuroscience}, combines neuroscience with mathematics and computer science to formulate theoretical principles governing the nervous system. 
While the term \textit{computational neuroscience} was introduced 1985, its roots date back to the early nineteen hundreds. 
One of the earliest theoretical discoveries in the field of neuroscience was done by Louis Lapique who introduced the \textit{integrate and fire} model of neuron \cite{lapique-1907}.
Later followed, among others, by Hodgkin and Huxley they laid the foundation of today's computational neuroscience.
The Hodgkin \& Huxley model explaining the action potential \cite{hodgkin1952quantitative}, even though extended in several ways since its formulation, remains one of the greatest achievements of neuroscience. \\

Modeling activity of single neurons, however, cannot capture the brain in its whole complexity.
Because the billions of neurons and other neural cells are constantly communicating with each other, their coordinated activity is another key to unlocking the brainâ€™s mysteries.
Methods capturing and interpreting such activity are therefore needed.
In 1924, Hans Berger was the first one to record human brain activity through electroencephalography (EEG).
Since then, many other recording techniques based on different principles emerged such as magnetoencephalography (MEG), functional magnetic resonance imaging (fMRI), positron emission tomography (PET), magnetic resonance spectroscopy (MRS), etc.  \\

But there is a long path from recording brain activity to understanding how it translates into processes the brain governs in humans.
One approach to formulate a relationship between brain signal and a certain process such as movement or sleep is called \textit{brain signal decoding} or also \textit{neural decoding}.
It studies what information is available in the electrical activity of neurons or networks of neurons through mapping patterns in the electrical activity onto external processes such as movement or sleep.
To crate such a mapping, first, brain signal is recorded simultaneously with a variable describing the process. 
Then a model predicting the variable based on the brain signal is built.
These models not only allow for a deeper understanding of the information contained in brain activity but have also direct clinical applications.
They are being used for predicting epileptic seizures \cite{epileptic-seizures-eeg}, Alzheimer disease diagnosis \cite{alzheimer-eeg}, classifying sleep stages \cite{sleep-stage-alg-comparison} or in Brain-computer interfacing (BCIs) \cite{ecog-bci, eeg-bci} .\\

Artificial neural networks, which elevated what is considered state-of-the-art across in various fields, most prominently computer vision \cite{dnn-computer-vision} and natural language processing \cite{dnn-nlp}, are being increasingly utilized as such models \cite{Roy-2019}. 
Their ability to process complex data in and end-to-end manner together with good prediction performance makes them suitable for decoding from brain signals. 


\section*{Motivation}
Utilizing recent advances in deep learning in movement decoding from (intracranial) EEG has brought considerable progress in this field.
In multiple cases, deep neural networks have been shown to be more effective when decoding movement from EEG and intracranial EEG than standard machine learning methods \cite{Zhang-2019, Hammer-2021, eeg-net, sleep-eegnet}.
Nevertheless, there is still room for considerable improvement in both, the decoding accuracies, interpretability and possibility of online applications. \\

To address these issues, Schirrmeister et al. \cite{schirrmeister-deep-2017} built several convolutional neural networks (CNNs) and assessed their suitability for movement classification from EEG.
Without the necessity to manually extract the input features, some of the architectures - including the Deep4Net, which is a central part of this thesis - were able to reach at least the same decoding accuracies as state-of-the-art filter bank common spatial patterns (FBCSP). 
Input-perturbation, output correlation visualization also showed the most informative spectral power features for the Deep4Net - the alpha, beta and high-gamma band.
EEG signals tend to have rather poor high-gamma resolution \cite{gamma-eeg-bad-resolution, tam-human-2019, scholg-presence-2002} and the ability of the network to use it was rather surprising. 
Because the Deep4Net has proven to be suitable for decoding from EEG, Hammer et al. \cite{Hammer-2021} employed it on a regression task, decoding hand velocity and absolute velocity (speed) from intracranial EEG. 
The high-gamma resolution in iEEG is higher than in EEG and it has been shown to be informative for speed decoding using linear regression on the same data \cite{hammer-predominance-2016}.
Interestingly, the input-perturbation output-correlation showed that the network failed to utilize the high-gamma frequency bands to the expected extent. \\

Without including it in the research paper, they briefly continued exploring this surprising fact.
Using a different visualization method, namely gradient visualization, they discovered a gradient peak at 83.33 Hz (in the high-gamma band).
But this is where their research ended. 
Multiple questions that arise from this -- Is the gradient peak significant or is it just an architecture artifact?
Why did the network not use the high-gamma?
Would other architectures use high-gamma in this setting?
Could we improve performance by forcing it to use high-gamma?
Is high-gamma indeed informative for speed decoding? -- remain to be answered.

\section*{Goals}
The aim of this thesis is to address the above outlined questions which can be summarized in the two following goals:

\begin{enumerate}
    \item Understanding which frequency bands are utilized for hand movement decoding with particular focus on the high-gamma band considering previous results from \cite{Hammer-2021} and \cite{schirrmeister-deep-2017} 
    \item Identifying which modifications to DNN training/architecture improve the utilization of information across useful frequency bands.
\end{enumerate}


In doing so, we will contribute to the interpretability of deep neural networks used for iEEG movement decoding.
By identifying informative frequency bands and optimizing the network architecture to use them effectively, we can also presumably improve the decoding performance.

