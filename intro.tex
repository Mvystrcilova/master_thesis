
\chapter{Introduction}
\label{chap:intr}

\section*{Historical context}
While mankind has been fascinated by the human mind for a long time, only the last 70 years of rapid technological advances finally allowed us to peer deep into the human brain.
New recordings techniques, theoretical models, and detailed simulations facilitated by the increase in computational power have opened new horizons in the field of neuroscience.
But to this day, a lot remains unclear about how the activity of billions of neural cells interconnected through a dense web of dynamic circuits translates into complex processes such as perception, movement, reasoning or learning.  \\

One of the recent subfields, namely \textit{computational neuroscience}, combines neuroscience with mathematics and computer science to formulate theoretical principles governing the nervous system. 
While the term \textit{computational neuroscience} was introduced 1985, its roots date back to the early nineteen hundreds. 
One of the earliest theoretical discoveries in the field of neuroscience was done by Louis Lapique who introduced the \textit{integrate and fire} model of neuron \cite{lapique-1907}.
Later followed, among others, by Hodgkin and Huxley they laid the foundation of today's computational neuroscience.
The Hodgkin \& Huxley model explaining the action potential \cite{hodgkin1952quantitative}, even though extended in several ways since its formulation, remains one of the greatest achievements of neuroscience. \\

Modeling activity of single neurons, however, cannot capture the brain in its whole complexity.
Because the billions of neurons and other neural cells are constantly communicating with each other, their coordinated activity is another key to unlocking the brainâ€™s mysteries.
Methods capturing and interpreting such activity are therefore needed.
In 1924, Hans Berger was the first one to record human brain activity through electroencephalography (EEG).
Since then, many other recording techniques based on different principles emerged such as magnetoencephalography (MEG), functional magnetic resonance imaging (fMRI), positron emission tomography (PET), magnetic resonance spectroscopy (MRS), etc.  \\

But there is a long path from recording brain activity to understanding how it translates into processes the brain governs in humans.
One approach to formulate a relationship between brain signal and a certain process such as movement or sleep is called \textit{brain signal decoding} or also \textit{neural decoding}.
It studies what information is available in the electrical activity of neurons or networks of neurons through mapping patterns in the electrical activity onto external processes such as movement or sleep.
To crate such a mapping, first, brain signal is recorded simultaneously with a variable describing the process. 
Then a model predicting the variable based on the brain signal is built.
These models not only allow for a deeper understanding of the information contained in brain activity but have also direct clinical applications.
They are being used for predicting epileptic seizures \cite{epileptic-seizures-eeg}, Alzheimer disease diagnosis \cite{alzheimer-eeg}, classifying sleep stages \cite{sleep-stage-alg-comparison} or in Brain-computer interfacing (BCIs) \cite{ecog-bci, eeg-bci} .\\

Artificial neural networks, which elevated what is considered state-of-the-art across in various fields, most prominently computer vision \cite{dnn-computer-vision} and natural language processing \cite{dnn-nlp}, are being increasingly utilized as such models \cite{Roy-2019}. 
Their ability to process complex data in and end-to-end manner together with good prediction performance makes them suitable for decoding from brain signals. 


\section*{Motivation}
Utilizing recent advances in deep learning (DL) in movement decoding from EEG have brought considerable progress in this field.
In multiple cases, deep neural networks have been shown to be more effective when decoding from EEG and intracranial EEG than standard machine learning methods \cite{Zhang-2019, eeg-net, sleep-eegnet}.
Nevertheless, there is still room for considerable improvement in both, the decoding accuracies, interpretability and possibility of online applications \cite{Roy-2019}. 
These issues are even more substantial in movement decoding from intracranial EEG decoding using deep learning. 
Because it is more difficult to acquire iEEG data, it is less researched but very prospective because of the higher signal-to-noise ration of iEEG signal compared to EEG \cite{volkova-review}. \\

To address these issues, Hammer et al. \cite{Hammer-2021} employed the Deep4Net - a convolutional neural network introduces in \cite{schirrmeister-deep-2017} - on a regression task, decoding hand velocity and absolute velocity (speed) from intracranial EEG. 
The Deep4Net was chosen because it has proven successful in movement-related classification tasks, reaching comparable accuracy with state-of-the-art methods without the necessity of manual feature extraction.
It was also shown to use spectral power modulations in the alpha, beta and for the first time in non-invasive EEG also high-gamma band for making its predictions. 
The fact that this architecture is able to extract information from the high-gamma band makes it suitable for iEEG decoding, where the high frequency resolution is better than in non-invasive EEG \cite{gamma-eeg-bad-resolution}. \\

While in \cite{Hammer-2021} the Deep4Net significantly outperformed multi-linear regression in the velocity and absolute velocity decoding, when visualizing which features it focuses on, it has not shown the expected interest in the high-gamma frequency modulations. 
In the context of previous findings on the same dataset, where high-gamma was found significant, especially for aboslute velocity decoding when using multilinear regression \cite{hammer-predominance-2016} and the fact that the Deep4Net architecture is able to extract information from the high-gamma frequency, the group briefly continued to explore this surprising finding.

Without including it in the research paper, using a different visualization method, namely gradient visualization, they discovered a gradient peak at 83.33~ Hz (in the high-gamma band).
But this is where their research ended. 
Multiple questions that arise from this -- Is the gradient peak significant or is it just an architecture artifact?
Why did the network not use the high-gamma?
Would other architectures use high-gamma in this setting?
Could we improve performance by forcing the network to use high-gamma?
Is high-gamma indeed informative for speed decoding? -- remain to be answered. \\
\\


\section*{Goals}
The aim of this thesis is to address the above outlined questions which can be summarized in the two following goals:

\begin{enumerate}
    \item Understanding which frequency bands are utilized for hand movement decoding with particular focus on the high-gamma band considering previous results from \cite{Hammer-2021} and \cite{schirrmeister-deep-2017} 
    \item Identifying which modifications to DNN training/architecture improve the utilization of information across useful frequency bands.
\end{enumerate}


In doing so, we will contribute to the interpretability of deep neural networks used for iEEG movement decoding.
By identifying informative frequency bands and optimizing the network architecture to use them effectively, we can also presumably improve the decoding performance.

