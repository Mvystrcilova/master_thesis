\chapter{Methodology}

\section{Dataset}
The dataset was the same as in the unpublished study of Hammer et al~\cite{}.
Modified with the authors permission, the description from~\cite{Hammer_2021} of the experiment settings,
and the pre-processing follows.
It was not a part of this thesis to perform the modifications described below.
We were provided with the pre-processed dataset.

\subsection{Movement task and kinematic variables}\label{subsec:movement-task-and-kinematic-variables}
A dataset that was already successfully used in several other iEEG studies to examine decoding of movement kinematic parameters \cite{Hammer_2021, 2016, 2013} was utilized for the purposes of this thesis.
The participants performed a motor task consisting in a car-driving computer simulation.
They controlled the position of the car on a computer screen using a steering wheel which they held in both hands.
The task was to keep the car on a curved road.
The road was random without any repetitions, following a low-pass filtered white noise trajectory.
During the movement task, the position of the car on the road was measured.
The position of the car linearly corresponded to the deflection of the steering wheel and was measured relative to the screen center, which corresponded to zero-deflection of the steering wheel.
Importantly, the control of the car's position was possible only in the horizontal dimension (left - right).
The upward movements of the car (vertical scrolling speed) were kept constant in each run of the game and adjusted for each subject individually.

The difficulty and the recording time of each subject was also adjusted based on the participant's motivation/ability to participate, lasting 25 ± 7 min (mean ± SD).
The car game difficulty was modified by the vertical scrolling speed of the car.
Therefore, to account for faster movements, the low-pass cutoff frequency was set to 10 Hz for smoothing the raw tracker data prior to the derivation of the kinematic parameters.
From the horizontal, 1-D trajectory, the following two kinematic parameters were derived:
1. velocity computed as a derivative of position, 2. speed as the absolute value of velocity.
Velocity thus contained the directional information in its sign;
for example, velocity values smaller than zero implicated movement to the left and vice versa, while speed indicated how fast the car was moving left or right (irrespective of its direction). T
he time-series of the kinematic parameters were resampled at 250 Hz and temporally aligned to the iEEG data.

\subsection{Recording}\label{subsec:recording}
The recordings were performed in the University Medical Centre in Freiburg, Germany and in the Motol University Hospital in Prague, Czech Republic.
The study included 12 epilepsy patients (6 male, age 19 - 50, mean = 33, SD = 10) all of which had intracranial EEG implantations.
Some of the implantations were placed in the region of the motor cortex.
The location of the electrodes was dependent solely on the needs for medical evaluation of their medication-resistant epilepsy.
Both sEEG and ECoG electrodes were present among patients.
Detailed information about electrode type and placement is presented in Table \ref{table_with_patient_info} and Figure \ref{fig}.

\subsection{Separation of motor and non-motor channels}\label{subsec:separation-of-motor-and-non-motor-channels}
A specific aim in the study of Hammer et al. was to show what the CNNs learned from the raw brain signals.
The hypothesis was that the CNNs would focus on information from the hand-motor cortex when solving a movement-related task.
To verify this hypothesis, the recorded channels were divided into two distinct, non-overlapping groups: 1. hand-motor channels and 2. non-motor channels.
The hand-motor channels induced a clear hand motor response after the electrical stimulation at low intensities underneath or around the electrode contacts.
The non-motor channels, on the other hand, produced no sensory/motor response after the stimulation.
Furthermore, a requirement of at least 1 cm distance from the motor and premotor areas (i.e. Area 4a, Area 4p and Area 6 from the SPM Anatomy toolbox52) had to be satisfied for a channel to be included in the non-motor group.
To this end, all MRI brain scans (T1-weighted sequence) were normalized to the MNI space and the electrodes' coordinates were read out from either the post-implantation MRI or CT scans53.
The average number of hand-motor channels was 13 ± 9 (mean ± SD), while there were 29 ± 18 (mean ± SD) non-motor channels.
Some electrodes did not fall into either of the hand-motor and non-motor channel groups (e.g. channels in the motor cortex the electrical stimulation of which induced leg-motor response).
These electrodes were then left out in some analysis, because the aim was to delineate the difference between the two distinct groups of channels (the hand-motor channel group and the non-motor channel group clearly far away from the motor cortex).


\subsection{IEEG data preprocessing}\label{subsec:ieeg-data-preprocessing}
The iEEG data preprocessing was also the same as in \cite{hammer_2021}. A comprehensive rejection of “epileptic” channels based on the information from the respective epilepsy centers was performed, because the primary aim was to investigate the physiological brain activity. Thus, the channels, i.e. those located in the seizure onset zone and/or containing a large number of inter-ictal epileptiform discharges, were rejected from this study (20 ± 13, mean ± SD over subjects Table \ref{}). All non-rejected iEEG channels (85 ± 28, mean +- SD) were referenced to their common average, high-pass filtered at 0.15 Hz (3rd order Butterworth filter), normalized to the inter-quartile range of each channel, and resampled to 250 Hz, to yield consistent data sets from the different recording systems used at both aforementioned epilepsy centers. The iEEG data were resampled to 250 Hz in order to emulate the same setup of the Deep4Net from \cite{Schirrmeister_2017}, which was successfully applied to demonstrate high-gamma (70 - 90 Hz) effects in decoding motor behaviour from non-invasive EEG. Importantly, any overfitting in the preprocessing was carefully avoided (i.e., all parameters of the preprocessing of the test set were estimated on the training set) and only acausal, finite impulse response filters were applied. Therefore, the decoding approach could be readily applied also in a closed-loop, online BMI.

The aligned iEEG and kinematic time-series were divided into 25-s long data segments. In order to minimize a potential influence of temporal correlations in neighbouring data parts, the segments had a 2-s margins in between each other. Additionally, the last two minutes of the recordings were left as a test set. The evaluation test set was not a part of the dataset that was utilized in this thesis.

\section{Deep4Net}\label{sec:deep4net}
The Deep4Net, which is freely available in the Braindecode library, was already shortly described in Section \ref{Background}. 
In this section, we describe it in more detail together with the architectural changes that need to be made when cropped decoding is used and how it relates to the changes we were making to the architecture throughout our research. 
We also focus on how classification and regression differ and what it means with respect to the architecture, its inputs and outputs. 

\subsection{Architecture}\label{subsec:architecture}
The architecture has been previously used in a number of EEG decoding tasks \cite{}.
It is implemented using PyTorch \footnote{}.
The input of the network is a 2D array with time-steps along one axis and channels along the other axis.
The architecture depicted in Figure \ref{figure_architecture} consists of four convolutional-max-pooling blocks and is designed so that a special first block can learn spatially global filters.
The following three standard blocks then allow for learning temporal hierarchies of local and global modulations \cite{Schirrmeister_2017}.
The first convolutional block is split into two parts.
One performs convolution over time and the second over the channels with weights for all possible electrode pairs using filters of the preceding temporal convolution.
Because there is no activation function between these two layers, they could be merged, but the authors emphasize the regularization function of this separation because it forces a separation of the linear transformation into a temporal convolution and a spatial filter.
The convolutional blocks start with a convolutional layer, then a batch normalization layer follows, after which a nonlinearity is added, in the case of the Deep4Net it is the exponential linear unit (ELU) function \cite{}.
Finally a max-pool layer closes the convolutional block.
An output layer, which is a softmax, comes last.
A scheme of this is in Figure \ref{figure}.
To use this network for regression which is what we are doing in this thesis, the only modification that needs to be done is removing the last softmax layer.
Otherwise, no special measures have to be taken.
Nevertheless, the way the output is interpreted changes.
This is further described in Section \ref{classification_regression_difference} after we provide important context about cropped decoding.

\subsection{Cropped decoding}
Cropped decoding as implemented in \cite{Schirrmeister} augments the dataset.
Instead of giving one trial and obtaining one prediction, the trial window is separated into multiple smaller overlapping sub-windows each of which produce a prediction.
In case of classification, these multiple outputs for one input window are then averaged to give the final prediction from which loss is calculated Fig \ref{figure}.
This way, the dataset is enlarged.
To avoid a longer training time, a trick with dilated convolution can be implemented.
This requires change in the architecture. As can be seen in Fig~\ref{architecture}, the convolutional layers have stride.
In order to implement a network which can process multiple crops at the same time and give an equivalent result as the network processing one crop at a time, the strides of the layers can be removed (set to 1) and instead replaced by an increasing dilation.
A visual explanation of this is in Fig \ref{}.
Importantly though, this only works if the network has no padding or only left padding.
Right padding would disrupt the equivalency of computation.
The algorithm to replace the strides with dilations is following: \\
\textbf{Algorithm}
\\
This means that for every network with stride and without right padding, there exists an equivalent network with dilations.
We will refer to it as a dilated network.
Nevertheless, this relationship is not symmetric.
For some dilated networks no networks with strides performing an equivalent computation exist.
An example of such a network is a network where in two consecutive layers with a dilation parameter, the first layer has bigger dilation than the second one.
This cannot happen if we follow the algorithm above~\ref{algorithm} thus, such a network was not derived from a network with strides.

In Schirrmeister et al~\cite{Schirrmeister_2017} the architectures were constructed in the space of the networks with stride and then converted into networks with dilations.
This leaves a whole set of architectures unexplored.
Namely those dilated networks which cannot be constructed from a network with stride.
It is important to point out that these dilated networks cannot be used for trial-wise decoding.
Nevertheless, as clearly follows from the next section~\ref{subsec:difference-between-deep4net-for-classification-and-regression}, this is no drawback for our task at hand.

\subsection{Difference between Deep4Net for classification and regression}\label{subsec:difference-between-deep4net-for-classification-and-regression}
We now describe the differences between using the Deep4Net for regression instead of classification.
In the classification task, one trial window was given as input having one gold label.
When using cropped decoding, the trial window was split into multiple shorter windows giving multiple outputs.
To get one output from these multiple outputs, the outputs were averaged to yield the final prediction.

In the case of regression we can also create an input window of a certain length and the label corresponding to it is the value of the kinematic variable at a certain time-point.
When we perform cropped decoding, we could just like for classification interpret all the outputs as belonging to the same prediction and averaging them.
But what Hammer et. al did, and also what we are implementing in this thesis, is interpreting each of these multiple outputs as consecutive values of the predicted variable which are directly used to calculate loss.
Therefore, there is no reason to perform trial-wise decoding and nothing prevents us from creating modified architectures for which it is impossible to create an equivalent network with strides.

The network is able to process varying input shapes.
It simply slides its convolutional filters over the input.
Therefore before training, the number of outputs needs to be calculated based on the size of the input window that was chosen.
The corresponding values of the predicted kinematic variables are cropped accordingly.
In this thesis, we used 1200 samples as input which corresponds to 4.8 seconds in time.
For the Deep4Net a window of 1200 samples gives 679 predictions.
Therefore, one prediction is made from 1200 - 679 + 1 = 522 samples measured before execution which translates to 2.088 seconds.
This is consistent with Hammer et al. where they used 2 second long segments.
Importantly to note, in Hammer et al. and also for the most part in this thesis, the input window predicting a time-point was shifted so that all the information used to decode this time-point happened prior to movement execution.
This makes the network suitable for online BCI.
