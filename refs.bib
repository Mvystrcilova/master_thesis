@book{knuth1979tex,
  title={TEX and METAFONT: New directions in typesetting},
  author={Knuth, Donald Ervin},
  year={1979},
  publisher={American Mathematical Society}
}

@book{lamport1994latex,
  title={LATEX: a document preparation system: user's guide and reference manual},
  author={Lamport, Leslie},
  year={1994},
  publisher={Addison-Wesley}
}

@book{glasman2010science,
  title={Science research writing for non-native speakers of English},
  author={Glasman-Deal, Hilary},
  year={2010},
  publisher={World Scientific}
}

@book{sparling1989english,
  title={English or Czenglish? Jak se vyhnout čechismům v angličtině},
  author={Sparling, Don},
  year={1989},
  publisher={Státní pedagogické nakladatelství}
}

@article{hammer-role-2013,
	title = {The role of {ECoG} magnitude and phase in decoding position, velocity, and acceleration during continuous motor behavior},
	volume = {7},
	issn = {1662-453X},
	url = {https://www.frontiersin.org/articles/10.3389/fnins.2013.00200/full},
	doi = {10.3389/fnins.2013.00200},
	abstract = {In neuronal population signals, including the electroencephalogram (EEG) and electrocorticogram (ECoG), the low-frequency component (LFC) is particularly informative about motor behavior and can be used for decoding movement parameters for brain-machine interface (BMI) applications. An idea previously expressed, but as of yet not quantitatively tested, is that it is the LFC phase that is the main source of decodable information. To test this issue, we analyzed human ECoG recorded during a game-like, one-dimensional, continuous motor task with a novel decoding method suitable for unfolding magnitude and phase explicitly into a complex-valued, time-frequency signal representation, enabling quantification of the decodable information within the temporal, spatial and frequency domains and allowing disambiguation of the phase contribution from that of the spectral magnitude. The decoding accuracy based only on phase information was substantially (at least 2 fold) and significantly higher than that based only on magnitudes for position, velocity and acceleration. The frequency profile of movement-related information in the ECoG data matched well with the frequency profile expected when assuming a close time-domain correlate of movement velocity in the ECoG, e.g., a (noisy) “copy” of hand velocity. No such match was observed with the frequency profiles expected when assuming a copy of either hand position or acceleration. There was also no indication of additional magnitude-based mechanisms encoding movement information in the LFC range. Thus, our study contributes to elucidating the nature of the informative low-frequency component of motor cortical population activity and may hence contribute to improve decoding strategies and BMI performance.},
	language = {English},
	urldate = {2021-04-24},
	journal = {Frontiers in Neuroscience},
	author = {Hammer, Jiri and Fischer, Jörg and Ruescher, Johanna and Schulze-Bonhage, Andreas and Aertsen, Ad and Ball, Tonio},
	year = {2013},
	keywords = {Decoding, Fourier de, brain-machine interfaces, low-frequency component, phase},
}

@article{kingma-adam-2017,
	title = {Adam: {A} {Method} for {Stochastic} {Optimization}},
	shorttitle = {Adam},
	url = {http://arxiv.org/abs/1412.6980},
	urldate = {2021-04-25},
	journal = {arXiv:1412.6980 [cs]},
	author = {Kingma, Diederik P. and Ba, Jimmy},
	month = jan,
	year = {2017},
	note = {arXiv: 1412.6980},
	keywords = {Computer Science - Machine Learning},
}

@article{clevert-elu-2016,
	title = {Fast and {Accurate} {Deep} {Network} {Learning} by {Exponential} {Linear} {Units} ({ELUs})},
	url = {http://arxiv.org/abs/1511.07289},
	urldate = {2021-04-24},
	journal = {arXiv:1511.07289 [cs]},
	author = {Clevert, Djork-Arné and Unterthiner, Thomas and Hochreiter, Sepp},
	month = feb,
	year = {2016},
	note = {arXiv: 1511.07289},
	keywords = {Computer Science - Machine Learning},
}


@article{eickhoff-new-2005,
	title = {A new {SPM} toolbox for combining probabilistic cytoarchitectonic maps and functional imaging data},
	volume = {25},
	issn = {10538119},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S105381190400792X},
	doi = {10.1016/j.neuroimage.2004.12.034},
	language = {en},
	number = {4},
	urldate = {2021-04-24},
	journal = {NeuroImage},
	author = {Eickhoff, Simon B. and Stephan, Klaas E. and Mohlberg, Hartmut and Grefkes, Christian and Fink, Gereon R. and Amunts, Katrin and Zilles, Karl},
	month = may,
	year = {2005},
	pages = {1325--1335},
}

@unpublished{Hammer-2021,
author  = {Hammer, Jiri and Schirrmeister, Robin T. and Hartmann, Kay and Schulze-Bondage, Andreas and Ball, Tonio},
title   = {Functional Integration and Segregation Emerging in Deep Convolutional Networks Trained for Brain Signal Decoding},
year    = {N.D.},
note    = {unpublished},
}


@article{liu-effects-2015,
	title = {The effects of spatial filtering and artifacts on electrocorticographic signals},
	volume = {12},
	issn = {1741-2560, 1741-2552},
	url = {https://iopscience.iop.org/article/10.1088/1741-2560/12/5/056008},
	doi = {10.1088/1741-2560/12/5/056008},
	number = {5},
	urldate = {2021-04-08},
	journal = {Journal of Neural Engineering},
	author = {Liu, Y and Coon, W G and Pesters, A de and Brunner, P and Schalk, G},
	month = oct,
	year = {2015},
	pages = {056008},
}

@article{lebedev-cortical-2005,
	title = {Cortical {Ensemble} {Adaptation} to {Represent} {Velocity} of an {Artificial} {Actuator} {Controlled} by a {Brain}-{Machine} {Interface}},
	volume = {25},
	copyright = {Copyright © 2005 Society for Neuroscience 0270-6474/05/254681-13.00/0},
	issn = {0270-6474, 1529-2401},
	url = {https://www.jneurosci.org/content/25/19/4681},
	doi = {10.1523/JNEUROSCI.4088-04.2005},
	language = {en},
	number = {19},
	urldate = {2021-04-08},
	journal = {Journal of Neuroscience},
	author = {Lebedev, Mikhail A. and Carmena, Jose M. and O'Doherty, Joseph E. and Zacksenhouse, Miriam and Henriquez, Craig S. and Principe, Jose C. and Nicolelis, Miguel A. L.},
	month = may,
	year = {2005},
	pmid = {15888644},
	keywords = {body schema, brain-machine interface, cortical plasticity, macaque monkey, motor cortex, motor learning},
	pages = {4681--4693},
}

@misc{scholg-presence-2002,
	title = {Presence {Research} and {EEG}},
	url = {https://www.semanticscholar.org/paper/Presence-Research-and-EEG-Scholg-Slater/18816255d88653d9bbaedb7a24c4394a6663c7a7},
	abstract = {The fields of presence research and electroencephalography (EEG) are related in, at least, two ways. Firstly, EEG can be used to analyse the neurophysiological phenomena related to presence research. For example, EEG might be useful to investigate the question of ‘breaks in presence’. Secondly, EEG can be used to control external devices with a so-called “brain computer interface” (BCI). Such a BCI might be also used for controlling a virtual environment.},
	language = {en},
	urldate = {2021-04-07},
	journal = {undefined},
	author = {Scholg, A. and Slater, M. and Pfurtscheller, G.},
	year = {2002},
}

@article{buzsaki-origin-2012,
	title = {The origin of extracellular fields and currents — {EEG}, {ECoG}, {LFP} and spikes},
	volume = {13},
	issn = {1471-003X, 1471-0048},
	url = {http://www.nature.com/articles/nrn3241},
	doi = {10.1038/nrn3241},
	language = {en},
	number = {6},
	urldate = {2021-04-07},
	journal = {Nature Reviews Neuroscience},
	author = {Buzsáki, György and Anastassiou, Costas A. and Koch, Christof},
	month = jun,
	year = {2012},
	pages = {407--420},
}

@article{tam-human-2019,
	title = {Human motor decoding from neural signals: a review},
	volume = {1},
	issn = {2524-4426},
	shorttitle = {Human motor decoding from neural signals},
	url = {https://doi.org/10.1186/s42490-019-0022-z},
	doi = {10.1186/s42490-019-0022-z},
	abstract = {Many people suffer from movement disability due to amputation or neurological diseases. Fortunately, with modern neurotechnology now it is possible to intercept motor control signals at various points along the neural transduction pathway and use that to drive external devices for communication or control. Here we will review the latest developments in human motor decoding. We reviewed the various strategies to decode motor intention from human and their respective advantages and challenges. Neural control signals can be intercepted at various points in the neural signal transduction pathway, including the brain (electroencephalography, electrocorticography, intracortical recordings), the nerves (peripheral nerve recordings) and the muscles (electromyography). We systematically discussed the sites of signal acquisition, available neural features, signal processing techniques and decoding algorithms in each of these potential interception points. Examples of applications and the current state-of-the-art performance were also reviewed. Although great strides have been made in human motor decoding, we are still far away from achieving naturalistic and dexterous control like our native limbs. Concerted efforts from material scientists, electrical engineers, and healthcare professionals are needed to further advance the field and make the technology widely available in clinical use.},
	number = {1},
	urldate = {2021-04-07},
	journal = {BMC Biomedical Engineering},
	author = {Tam, Wing-kin and Wu, Tong and Zhao, Qi and Keefer, Edward and Yang, Zhi},
	month = sep,
	year = {2019},
	keywords = {Brain-machine interfaces, Motor decoding, Neural signal processing, Neuroprosthesis},
	pages = {22},
}

@article{hammer-predominance-2016,
	title = {Predominance of {Movement} {Speed} {Over} {Direction} in {Neuronal} {Population} {Signals} of {Motor} {Cortex}: {Intracranial} {EEG} {Data} and {A} {Simple} {Explanatory} {Model}},
	volume = {26},
	issn = {1047-3211, 1460-2199},
	shorttitle = {Predominance of {Movement} {Speed} {Over} {Direction} in {Neuronal} {Population} {Signals} of {Motor} {Cortex}},
	url = {https://academic.oup.com/cercor/article-lookup/doi/10.1093/cercor/bhw033},
	doi = {10.1093/cercor/bhw033},
	language = {en},
	number = {6},
	urldate = {2021-01-21},
	journal = {Cerebral Cortex},
	author = {Hammer, Jiří and Pistohl, Tobias and Fischer, Jörg and Kršek, Pavel and Tomášek, Martin and Marusič, Petr and Schulze-Bonhage, Andreas and Aertsen, Ad and Ball, Tonio},
	month = jun,
	year = {2016},
	pages = {2863--2881},
}

@article{zeiler-visualizing-2013,
	title = {Visualizing and {Understanding} {Convolutional} {Networks}},
	url = {http://arxiv.org/abs/1311.2901},
	abstract = {Large Convolutional Network models have recently demonstrated impressive classification performance on the ImageNet benchmark. However there is no clear understanding of why they perform so well, or how they might be improved. In this paper we address both issues. We introduce a novel visualization technique that gives insight into the function of intermediate feature layers and the operation of the classifier. We also perform an ablation study to discover the performance contribution from different model layers. This enables us to find model architectures that outperform Krizhevsky {\textbackslash}etal on the ImageNet classification benchmark. We show our ImageNet model generalizes well to other datasets: when the softmax classifier is retrained, it convincingly beats the current state-of-the-art results on Caltech-101 and Caltech-256 datasets.},
	urldate = {2020-11-27},
	journal = {arXiv:1311.2901 [cs]},
	author = {Zeiler, Matthew D. and Fergus, Rob},
	month = nov,
	year = {2013},
	note = {arXiv: 1311.2901},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
}

@article{springenberg-striving-2015,
	title = {Striving for {Simplicity}: {The} {All} {Convolutional} {Net}},
	shorttitle = {Striving for {Simplicity}},
	url = {http://arxiv.org/abs/1412.6806},
	abstract = {Most modern convolutional neural networks (CNNs) used for object recognition are built using the same principles: Alternating convolution and max-pooling layers followed by a small number of fully connected layers. We re-evaluate the state of the art for object recognition from small images with convolutional networks, questioning the necessity of different components in the pipeline. We find that max-pooling can simply be replaced by a convolutional layer with increased stride without loss in accuracy on several image recognition benchmarks. Following this finding -- and building on other recent work for finding simple network structures -- we propose a new architecture that consists solely of convolutional layers and yields competitive or state of the art performance on several object recognition datasets (CIFAR-10, CIFAR-100, ImageNet). To analyze the network we introduce a new variant of the "deconvolution approach" for visualizing features learned by CNNs, which can be applied to a broader range of network structures than existing approaches.},
	urldate = {2020-11-27},
	journal = {arXiv:1412.6806 [cs]},
	author = {Springenberg, Jost Tobias and Dosovitskiy, Alexey and Brox, Thomas and Riedmiller, Martin},
	month = apr,
	year = {2015},
	note = {arXiv: 1412.6806},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@article{bach-pixel-wise-2015,
	title = {On {Pixel}-{Wise} {Explanations} for {Non}-{Linear} {Classifier} {Decisions} by {Layer}-{Wise} {Relevance} {Propagation}},
	volume = {10},
	issn = {1932-6203},
	url = {https://dx.plos.org/10.1371/journal.pone.0130140},
	doi = {10.1371/journal.pone.0130140},
	language = {en},
	number = {7},
	urldate = {2020-11-24},
	journal = {PLOS ONE},
	author = {Bach, Sebastian and Binder, Alexander and Montavon, Grégoire and Klauschen, Frederick and Müller, Klaus-Robert and Samek, Wojciech},
	editor = {Suarez, Oscar Deniz},
	month = jul,
	year = {2015},
	pages = {e0130140},
}

@book{samek-explainable-2019,
	title = {Explainable {AI}: interpreting, explaining and visualizing deep learning},
	isbn = {9783030289546 9783030289553},
	shorttitle = {Explainable {AI}},
	url = {https://doi.org/10.1007/978-3-030-28954-6},
	abstract = {The development of "intelligent" systems that can take decisions and perform autonomously might lead to faster and more consistent decisions. A limiting factor for a broader adoption of AI technology is the inherent risks that come with giving up human control and oversight to "intelligent" machines. Forsensitive tasks involving critical infrastructures and affecting human well-being or health, it is crucial to limit the possibility of improper, non-robust and unsafe decisions and actions. Before deploying an AI system, we see a strong need to validate its behavior, and thus establish guarantees that it will continue to perform as expected when deployed in a real-world environment. In pursuit of that objective, ways for humans to verify the agreement between the AI decision structure and their own ground-truth knowledge have been explored. Explainable AI (XAI) has developed as a subfield of AI, focused on exposing complex AI models to humans in a systematic and interpretable manner. The 22 chapters included in this book provide a timely snapshot of algorithms, theory, and applications of interpretable and explainable AI and AI techniques that have been proposed recently reflecting the current discourse in this field and providing directions of future development. The book is organized in six parts: towards AI transparency; methods for interpreting AI systems; explaining the decisions of AI systems; evaluating interpretability and explanations; applications of explainable AI; and software for explainable AI. --},
	language = {English},
	urldate = {2020-11-16},
	author = {Samek, Wojciech and Montavon, Grégoire and Vedaldi, Andrea and Hansen, Lars Kai and Müller, Klaus-Robert},
	year = {2019},
	note = {OCLC: 1120722055},
}

@article{eitel-uncovering-2019,
	title = {Uncovering convolutional neural network decisions for diagnosing multiple sclerosis on conventional {MRI} using layer-wise relevance propagation},
	volume = {24},
	issn = {22131582},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2213158219303535},
	doi = {10.1016/j.nicl.2019.102003},
	language = {en},
	urldate = {2020-11-23},
	journal = {NeuroImage: Clinical},
	author = {Eitel, Fabian and Soehler, Emily and Bellmann-Strobl, Judith and Brandt, Alexander U. and Ruprecht, Klemens and Giess, René M. and Kuchling, Joseph and Asseyer, Susanna and Weygandt, Martin and Haynes, John-Dylan and Scheel, Michael and Paul, Friedemann and Ritter, Kerstin},
	year = {2019},
	pages = {102003},
}

@article{sundararajan-axiomatic-2017,
	title = {Axiomatic {Attribution} for {Deep} {Networks}},
	url = {http://arxiv.org/abs/1703.01365},
	abstract = {We study the problem of attributing the prediction of a deep network to its input features, a problem previously studied by several other works. We identify two fundamental axioms---Sensitivity and Implementation Invariance that attribution methods ought to satisfy. We show that they are not satisfied by most known attribution methods, which we consider to be a fundamental weakness of those methods. We use the axioms to guide the design of a new attribution method called Integrated Gradients. Our method requires no modification to the original network and is extremely simple to implement; it just needs a few calls to the standard gradient operator. We apply this method to a couple of image models, a couple of text models and a chemistry model, demonstrating its ability to debug networks, to extract rules from a network, and to enable users to engage with models better.},
	urldate = {2020-11-23},
	journal = {arXiv:1703.01365 [cs]},
	author = {Sundararajan, Mukund and Taly, Ankur and Yan, Qiqi},
	month = jun,
	year = {2017},
	note = {arXiv: 1703.01365},
	keywords = {Computer Science - Machine Learning},
}

@article{kindermans-learning-2017,
	title = {Learning how to explain neural networks: {PatternNet} and {PatternAttribution}},
	shorttitle = {Learning how to explain neural networks},
	url = {http://arxiv.org/abs/1705.05598},
	abstract = {DeConvNet, Guided BackProp, LRP, were invented to better understand deep neural networks. We show that these methods do not produce the theoretically correct explanation for a linear model. Yet they are used on multi-layer networks with millions of parameters. This is a cause for concern since linear models are simple neural networks. We argue that explanation methods for neural nets should work reliably in the limit of simplicity, the linear models. Based on our analysis of linear models we propose a generalization that yields two explanation techniques (PatternNet and PatternAttribution) that are theoretically sound for linear models and produce improved explanations for deep networks.},
	urldate = {2020-11-20},
	journal = {arXiv:1705.05598 [cs, stat]},
	author = {Kindermans, Pieter-Jan and Schütt, Kristof T. and Alber, Maximilian and Müller, Klaus-Robert and Erhan, Dumitru and Kim, Been and Dähne, Sven},
	month = oct,
	year = {2017},
	note = {arXiv: 1705.05598},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{fong-interpretable-2017,
	title = {Interpretable {Explanations} of {Black} {Boxes} by {Meaningful} {Perturbation}},
	url = {http://arxiv.org/abs/1704.03296},
	doi = {10.1109/ICCV.2017.371},
	abstract = {As machine learning algorithms are increasingly applied to high impact yet high risk tasks, such as medical diagnosis or autonomous driving, it is critical that researchers can explain how such algorithms arrived at their predictions. In recent years, a number of image saliency methods have been developed to summarize where highly complex neural networks "look" in an image for evidence for their predictions. However, these techniques are limited by their heuristic nature and architectural constraints. In this paper, we make two main contributions: First, we propose a general framework for learning different kinds of explanations for any black box algorithm. Second, we specialise the framework to find the part of an image most responsible for a classifier decision. Unlike previous works, our method is model-agnostic and testable because it is grounded in explicit and interpretable image perturbations.},
	urldate = {2020-11-20},
	journal = {2017 IEEE International Conference on Computer Vision (ICCV)},
	author = {Fong, Ruth and Vedaldi, Andrea},
	month = oct,
	year = {2017},
	note = {arXiv: 1704.03296},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
	pages = {3449--3457},
}

@article{guidotti-survey-2019,
	title = {A {Survey} of {Methods} for {Explaining} {Black} {Box} {Models}},
	volume = {51},
	issn = {0360-0300, 1557-7341},
	url = {https://dl.acm.org/doi/10.1145/3236009},
	doi = {10.1145/3236009},
	language = {en},
	number = {5},
	urldate = {2020-11-19},
	journal = {ACM Computing Surveys},
	author = {Guidotti, Riccardo and Monreale, Anna and Ruggieri, Salvatore and Turini, Franco and Giannotti, Fosca and Pedreschi, Dino},
	month = jan,
	year = {2019},
	pages = {1--42},
}

@article{yang-visual-2018,
	title = {Visual {Explanations} {From} {Deep} {3D} {Convolutional} {Neural} {Networks} for {Alzheimer}'s {Disease} {Classification}},
	url = {http://arxiv.org/abs/1803.02544},
	abstract = {We develop three efficient approaches for generating visual explanations from 3D convolutional neural networks (3D-CNNs) for Alzheimer's disease classification. One approach conducts sensitivity analysis on hierarchical 3D image segmentation, and the other two visualize network activations on a spatial map. Visual checks and a quantitative localization benchmark indicate that all approaches identify important brain parts for Alzheimer's disease diagnosis. Comparative analysis show that the sensitivity analysis based approach has difficulty handling loosely distributed cerebral cortex, and approaches based on visualization of activations are constrained by the resolution of the convolutional layer. The complementarity of these methods improves the understanding of 3D-CNNs in Alzheimer's disease classification from different perspectives.},
	urldate = {2020-11-19},
	journal = {arXiv:1803.02544 [cs, stat]},
	author = {Yang, Chengliang and Rangarajan, Anand and Ranka, Sanjay},
	month = jul,
	year = {2018},
	note = {arXiv: 1803.02544},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Statistics - Machine Learning},
}

@inproceedings{rieke-visualizing-2018,
	address = {Cham},
	series = {Lecture {Notes} in {Computer} {Science}},
	title = {Visualizing {Convolutional} {Networks} for {MRI}-{Based} {Diagnosis} of {Alzheimer}’s {Disease}},
	isbn = {9783030026288},
	doi = {10.1007/978-3-030-02628-8_3},
	abstract = {Visualizing and interpreting convolutional neural networks (CNNs) is an important task to increase trust in automatic medical decision making systems. In this study, we train a 3D CNN to detect Alzheimer’s disease based on structural MRI scans of the brain. Then, we apply four different gradient-based and occlusion-based visualization methods that explain the network’s classification decisions by highlighting relevant areas in the input image. We compare the methods qualitatively and quantitatively. We find that all four methods focus on brain regions known to be involved in Alzheimer’s disease, such as inferior and middle temporal gyrus. While the occlusion-based methods focus more on specific regions, the gradient-based methods pick up distributed relevance patterns. Additionally, we find that the distribution of relevance varies across patients, with some having a stronger focus on the temporal lobe, whereas for others more cortical areas are relevant. In summary, we show that applying different visualization methods is important to understand the decisions of a CNN, a step that is crucial to increase clinical impact and trust in computer-based decision support systems.},
	language = {en},
	booktitle = {Understanding and {Interpreting} {Machine} {Learning} in {Medical} {Image} {Computing} {Applications}},
	publisher = {Springer International Publishing},
	author = {Rieke, Johannes and Eitel, Fabian and Weygandt, Martin and Haynes, John-Dylan and Ritter, Kerstin},
	editor = {Stoyanov, Danail and Taylor, Zeike and Kia, Seyed Mostafa and Oguz, Ipek and Reyes, Mauricio and Martel, Anne and Maier-Hein, Lena and Marquand, Andre F. and Duchesnay, Edouard and Löfstedt, Tommy and Landman, Bennett and Cardoso, M. Jorge and Silva, Carlos A. and Pereira, Sergio and Meier, Raphael},
	year = {2018},
	keywords = {3D , Alzheimer , Brain , CNN , Deep learning , MRI , Visualization },
	pages = {24--31},
}

@article{zintgraf-visualizing-2017,
	title = {Visualizing {Deep} {Neural} {Network} {Decisions}: {Prediction} {Difference} {Analysis}},
	shorttitle = {Visualizing {Deep} {Neural} {Network} {Decisions}},
	url = {http://arxiv.org/abs/1702.04595},
	abstract = {This article presents the prediction difference analysis method for visualizing the response of a deep neural network to a specific input. When classifying images, the method highlights areas in a given input image that provide evidence for or against a certain class. It overcomes several shortcoming of previous methods and provides great additional insight into the decision making process of classifiers. Making neural network decisions interpretable through visualization is important both to improve models and to accelerate the adoption of black-box classifiers in application areas such as medicine. We illustrate the method in experiments on natural images (ImageNet data), as well as medical images (MRI brain scans).},
	urldate = {2020-11-17},
	journal = {arXiv:1702.04595 [cs]},
	author = {Zintgraf, Luisa M. and Cohen, Taco S. and Adel, Tameem and Welling, Max},
	month = feb,
	year = {2017},
	note = {arXiv: 1702.04595},
	keywords = {Computer Science - Artificial Intelligence, Computer Science - Computer Vision and Pattern Recognition},
}

@article{sixt-when-2020,
	title = {When {Explanations} {Lie}: {Why} {Many} {Modified} {BP} {Attributions} {Fail}},
	shorttitle = {When {Explanations} {Lie}},
	url = {http://arxiv.org/abs/1912.09818},
	abstract = {Attribution methods aim to explain a neural network's prediction by highlighting the most relevant image areas. A popular approach is to backpropagate (BP) a custom relevance score using modified rules, rather than the gradient. We analyze an extensive set of modified BP methods: Deep Taylor Decomposition, Layer-wise Relevance Propagation (LRP), Excitation BP, PatternAttribution, DeepLIFT, Deconv, RectGrad, and Guided BP. We find empirically that the explanations of all mentioned methods, except for DeepLIFT, are independent of the parameters of later layers. We provide theoretical insights for this surprising behavior and also analyze why DeepLIFT does not suffer from this limitation. Empirically, we measure how information of later layers is ignored by using our new metric, cosine similarity convergence (CSC). The paper provides a framework to assess the faithfulness of new and existing modified BP methods theoretically and empirically. For code see: https://github.com/berleon/when-explanations-lie},
	urldate = {2020-11-17},
	journal = {arXiv:1912.09818 [cs, stat]},
	author = {Sixt, Leon and Granz, Maximilian and Landgraf, Tim},
	month = aug,
	year = {2020},
	note = {arXiv: 1912.09818},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{ancona-towards-2018,
	title = {Towards better understanding of gradient-based attribution methods for {Deep} {Neural} {Networks}},
	url = {http://arxiv.org/abs/1711.06104},
	abstract = {Understanding the flow of information in Deep Neural Networks (DNNs) is a challenging problem that has gain increasing attention over the last few years. While several methods have been proposed to explain network predictions, there have been only a few attempts to compare them from a theoretical perspective. What is more, no exhaustive empirical comparison has been performed in the past. In this work, we analyze four gradient-based attribution methods and formally prove conditions of equivalence and approximation between them. By reformulating two of these methods, we construct a unified framework which enables a direct comparison, as well as an easier implementation. Finally, we propose a novel evaluation metric, called Sensitivity-n and test the gradient-based attribution methods alongside with a simple perturbation-based attribution method on several datasets in the domains of image and text classification, using various network architectures.},
	urldate = {2020-11-16},
	journal = {arXiv:1711.06104 [cs, stat]},
	author = {Ancona, Marco and Ceolini, Enea and Öztireli, Cengiz and Gross, Markus},
	month = mar,
	year = {2018},
	note = {arXiv: 1711.06104},
	keywords = {Computer Science - Machine Learning, Statistics - Machine Learning},
}

@article{rafegas-understanding-2020,
	title = {Understanding trained {CNNs} by indexing neuron selectivity},
	volume = {136},
	issn = {01678655},
	url = {http://arxiv.org/abs/1702.00382},
	doi = {10.1016/j.patrec.2019.10.013},
	abstract = {The impressive performance of Convolutional Neural Networks (CNNs) when solving different vision problems is shadowed by their black-box nature and our consequent lack of understanding of the representations they build and how these representations are organized. To help understanding these issues, we propose to describe the activity of individual neurons by their Neuron Feature visualization and quantify their inherent selectivity with two specific properties. We explore selectivity indexes for: an image feature (color); and an image label (class membership). Our contribution is a framework to seek or classify neurons by indexing on these selectivity properties. It helps to find color selective neurons, such as a red-mushroom neuron in layer Conv4 or class selective neurons such as dog-face neurons in layer Conv5 in VGG-M, and establishes a methodology to derive other selectivity properties. Indexing on neuron selectivity can statistically draw how features and classes are represented through layers in a moment when the size of trained nets is growing and automatic tools to index neurons can be helpful.},
	urldate = {2020-11-17},
	journal = {Pattern Recognition Letters},
	author = {Rafegas, Ivet and Vanrell, Maria and Alexandre, Luis A. and Arias, Guillem},
	month = aug,
	year = {2020},
	note = {arXiv: 1702.00382},
	keywords = {Computer Science - Computer Vision and Pattern Recognition},
	pages = {318--325},
}

@inproceedings{goodfellow-towards-2018,
	title = {Towards {Understanding} {ECG} {Rhythm} {Classification} {Using} {Convolutional} {Neural} {Networks} and {Attention} {Mappings}},
	abstract = {In this study, a deep convolutional neural network was trained to classify single lead ECG waveforms as either Normal Sinus Rhythm, Atrial Fibrillation, or Other Rhythm. The dataset consisted of 12,186 labeled waveforms donated by AliveCor R © for use in the 2017 Physionet Challenge. The study was run in two phases, the first to generate a classifier that performed at a level comparable to the top submission of the 2017 Physionet Challenge, and the second to extract class activation mappings to help better understand which areas of the waveform the model was focusing on when making a classification. The convolutional neural network had 13 layers, including dilated convolutions, max pooling, ReLU activation, batch normalization, and dropout. Class activation maps were generated using a global average pooling layer before the softmax layer. The model generated the following average scores, across all rhythm classes, on the validation dataset: precision=0.84, recall=0.85, F1=0.84, and accuracy=0.88. For the Normal Sinus Rhythm class activation maps, we observed roughly constant attention, while for the Other Rhythm class, we observed attention spikes associated with premature beats. The class activation maps would allow for some level of interpretability by clinicians, which will likely be important for the adoption of these techniques to augment diagnosis. c © 2018 S.D. Goodfellow, A. Goodwin, R. Greer, P.C. Laussen, M. Mazwi \& D. Eytan. ECG Classification Using Convolutional Neural Networks and Attention Mappings},
	booktitle = {{MLHC}},
	author = {Goodfellow, S. and Goodwin, A. and Greer, Robert and Laussen, P. and Mazwi, Mjaye and Eytan, D.},
	year = {2018},
}

@article{angrick-speech-2018,
	title = {Speech {Synthesis} from {ECoG} using {Densely} {Connected} {3D} {Convolutional} {Neural} {Networks}},
	copyright = {© 2018, Posted by Cold Spring Harbor Laboratory. The copyright holder for this pre-print is the author. All rights reserved. The material may not be redistributed, re-used or adapted without the author's permission.},
	url = {https://www.biorxiv.org/content/10.1101/478644v1},
	doi = {10.1101/478644},
	abstract = {{\textless}h3{\textgreater}Abstract{\textless}/h3{\textgreater} {\textless}h3{\textgreater}Objective{\textless}/h3{\textgreater} {\textless}p{\textgreater}Direct synthesis of speech from neural signals could provide a fast and natural way of communication to people with neurological diseases. Invasively-measured brain activity (electrocorticography; ECoG) supplies the necessary temporal and spatial resolution to decode fast and complex processes such as speech production. A number of impressive advances in speech decoding using neural signals have been achieved in recent years, but the complex dynamics are still not fully understood. However, it is unlikely that simple linear models can capture the relation between neural activity and continuous spoken speech.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Approach{\textless}/h3{\textgreater} {\textless}p{\textgreater}Here we show that deep neural networks can be used to map ECoG from speech production areas onto an intermediate representation of speech (logMel spectrogram). The proposed method uses a densely connected convolutional neural network topology which is well-suited to work with the small amount of data available from each participant.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Main results{\textless}/h3{\textgreater} {\textless}p{\textgreater}In a study with six participants, we achieved correlations up to \textit{r} = 0.69 between the reconstructed and original logMel spectrograms. We transfered our prediction back into an audible waveform by applying a Wavenet vocoder. The vocoder was conditioned on logMel features that harnessed a much larger, pre-existing data corpus to provide the most natural acoustic output.{\textless}/p{\textgreater}{\textless}h3{\textgreater}Significance{\textless}/h3{\textgreater} {\textless}p{\textgreater}To the best of our knowledge, this is the first time that high-quality speech has been reconstructed from neural recordings during speech production using deep neural networks.{\textless}/p{\textgreater}},
	language = {en},
	urldate = {2020-11-16},
	journal = {bioRxiv},
	author = {Angrick, Miguel and Herff, Christian and Mugler, Emily and Tate, Matthew C. and Slutzky, Marc W. and Krusienski, Dean J. and Schultz, Tanja},
	month = nov,
	year = {2018},
	pages = {478644},
}

@article{montavon-methods-2018,
	title = {Methods for interpreting and understanding deep neural networks},
	volume = {73},
	issn = {10512004},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1051200417302385},
	doi = {10.1016/j.dsp.2017.10.011},
	language = {en},
	urldate = {2020-11-16},
	journal = {Digital Signal Processing},
	author = {Montavon, Grégoire and Samek, Wojciech and Müller, Klaus-Robert},
	month = feb,
	year = {2018},
	pages = {1--15},
}

@article{shrikumar-learning-2019,
	title = {Learning {Important} {Features} {Through} {Propagating} {Activation} {Differences}},
	url = {http://arxiv.org/abs/1704.02685},
	abstract = {The purported "black box" nature of neural networks is a barrier to adoption in applications where interpretability is essential. Here we present DeepLIFT (Deep Learning Important FeaTures), a method for decomposing the output prediction of a neural network on a specific input by backpropagating the contributions of all neurons in the network to every feature of the input. DeepLIFT compares the activation of each neuron to its 'reference activation' and assigns contribution scores according to the difference. By optionally giving separate consideration to positive and negative contributions, DeepLIFT can also reveal dependencies which are missed by other approaches. Scores can be computed efficiently in a single backward pass. We apply DeepLIFT to models trained on MNIST and simulated genomic data, and show significant advantages over gradient-based methods. Video tutorial: http://goo.gl/qKb7pL, ICML slides: bit.ly/deeplifticmlslides, ICML talk: https://vimeo.com/238275076, code: http://goo.gl/RM8jvH.},
	urldate = {2020-11-16},
	journal = {arXiv:1704.02685 [cs]},
	author = {Shrikumar, Avanti and Greenside, Peyton and Kundaje, Anshul},
	month = oct,
	year = {2019},
	note = {arXiv: 1704.02685},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Computer Science - Machine Learning, Computer Science - Neural and Evolutionary Computing},
}

@inproceedings{zhou-learning-2016,
	address = {Las Vegas, NV, USA},
	title = {Learning {Deep} {Features} for {Discriminative} {Localization}},
	isbn = {9781467388511},
	url = {http://ieeexplore.ieee.org/document/7780688/},
	doi = {10.1109/CVPR.2016.319},
	urldate = {2020-11-16},
	booktitle = {2016 {IEEE} {Conference} on {Computer} {Vision} and {Pattern} {Recognition} ({CVPR})},
	publisher = {IEEE},
	author = {Zhou, Bolei and Khosla, Aditya and Lapedriza, Agata and Oliva, Aude and Torralba, Antonio},
	month = jun,
	year = {2016},
	pages = {2921--2929},
}

@article{sturm-interpretable-2016,
	title = {Interpretable {Deep} {Neural} {Networks} for {Single}-{Trial} {EEG} {Classification}},
	url = {http://arxiv.org/abs/1604.08201},
	abstract = {Background: In cognitive neuroscience the potential of Deep Neural Networks (DNNs) for solving complex classification tasks is yet to be fully exploited. The most limiting factor is that DNNs as notorious 'black boxes' do not provide insight into neurophysiological phenomena underlying a decision. Layer-wise Relevance Propagation (LRP) has been introduced as a novel method to explain individual network decisions. New Method: We propose the application of DNNs with LRP for the first time for EEG data analysis. Through LRP the single-trial DNN decisions are transformed into heatmaps indicating each data point's relevance for the outcome of the decision. Results: DNN achieves classification accuracies comparable to those of CSP-LDA. In subjects with low performance subject-to-subject transfer of trained DNNs can improve the results. The single-trial LRP heatmaps reveal neurophysiologically plausible patterns, resembling CSP-derived scalp maps. Critically, while CSP patterns represent class-wise aggregated information, LRP heatmaps pinpoint neural patterns to single time points in single trials. Comparison with Existing Method(s): We compare the classification performance of DNNs to that of linear CSP-LDA on two data sets related to motor-imaginery BCI. Conclusion: We have demonstrated that DNN is a powerful non-linear tool for EEG analysis. With LRP a new quality of high-resolution assessment of neural activity can be reached. LRP is a potential remedy for the lack of interpretability of DNNs that has limited their utility in neuroscientific applications. The extreme specificity of the LRP-derived heatmaps opens up new avenues for investigating neural activity underlying complex perception or decision-related processes.},
	urldate = {2020-11-16},
	journal = {arXiv:1604.08201 [cs, stat]},
	author = {Sturm, Irene and Bach, Sebastian and Samek, Wojciech and Müller, Klaus-Robert},
	month = apr,
	year = {2016},
	note = {arXiv: 1604.08201},
	keywords = {Computer Science - Neural and Evolutionary Computing, Statistics - Machine Learning},
}

@article{lawhern-eegnet-2018,
	title = {{EEGNet}: a compact convolutional neural network for {EEG}-based brain–computer interfaces},
	volume = {15},
	issn = {1741-2560, 1741-2552},
	shorttitle = {{EEGNet}},
	url = {https://iopscience.iop.org/article/10.1088/1741-2552/aace8c},
	doi = {10.1088/1741-2552/aace8c},
	number = {5},
	urldate = {2020-11-16},
	journal = {Journal of Neural Engineering},
	author = {Lawhern, Vernon J and Solon, Amelia J and Waytowich, Nicholas R and Gordon, Stephen M and Hung, Chou P and Lance, Brent J},
	month = oct,
	year = {2018},
	pages = {056013},
}

@article{meisel-identifying-2019,
	title = {Identifying signal-dependent information about the preictal state: {A} comparison across {ECoG}, {EEG} and {EKG} using deep learning},
	volume = {45},
	issn = {23523964},
	shorttitle = {Identifying signal-dependent information about the preictal state},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S2352396419304360},
	doi = {10.1016/j.ebiom.2019.07.001},
	language = {en},
	urldate = {2020-11-16},
	journal = {EBioMedicine},
	author = {Meisel, Christian and Bailey, Kimberlyn A.},
	month = jul,
	year = {2019},
	pages = {422--431},
}

@article{hartmann-hierarchical-2018,
	title = {Hierarchical internal representation of spectral features in deep convolutional networks trained for {EEG} decoding},
	url = {http://arxiv.org/abs/1711.07792},
	doi = {10.1109/IWW-BCI.2018.8311493},
	abstract = {Recently, there is increasing interest and research on the interpretability of machine learning models, for example how they transform and internally represent EEG signals in Brain-Computer Interface (BCI) applications. This can help to understand the limits of the model and how it may be improved, in addition to possibly provide insight about the data itself. Schirrmeister et al. (2017) have recently reported promising results for EEG decoding with deep convolutional neural networks (ConvNets) trained in an end-to-end manner and, with a causal visualization approach, showed that they learn to use spectral amplitude changes in the input. In this study, we investigate how ConvNets represent spectral features through the sequence of intermediate stages of the network. We show higher sensitivity to EEG phase features at earlier stages and higher sensitivity to EEG amplitude features at later stages. Intriguingly, we observed a specialization of individual stages of the network to the classical EEG frequency bands alpha, beta, and high gamma. Furthermore, we find first evidence that particularly in the last convolutional layer, the network learns to detect more complex oscillatory patterns beyond spectral phase and amplitude, reminiscent of the representation of complex visual features in later layers of ConvNets in computer vision tasks. Our findings thus provide insights into how ConvNets hierarchically represent spectral EEG features in their intermediate layers and suggest that ConvNets can exploit and might help to better understand the compositional structure of EEG time series.},
	urldate = {2020-11-16},
	journal = {2018 6th International Conference on Brain-Computer Interface (BCI)},
	author = {Hartmann, Kay Gregor and Schirrmeister, Robin Tibor and Ball, Tonio},
	month = jan,
	year = {2018},
	note = {arXiv: 1711.07792},
	keywords = {Computer Science - Machine Learning, Quantitative Biology - Neurons and Cognition, Statistics - Machine Learning},
	pages = {1--6},
}

@techreport{petrosuan-decoding-2020,
	type = {preprint},
	title = {Decoding neural signals and discovering their representations with a compact and interpretable convolutional neural network},
	url = {http://biorxiv.org/lookup/doi/10.1101/2020.06.02.129114},
	abstract = {A
            bstract

          Brain-computer interfaces (BCIs) decode information from neural activity and send it to external devices. In recent years, we have seen an emergence of new algorithms for BCI decoding including those based on the deep-learning principles. Here we describe a compact convolutional network-based architecture for adaptive decoding of electrocorticographic (ECoG) data into finger kinematics. We also propose a theoretically justified approach to interpreting the spatial and temporal weights in the architectures that combine adaptation in both space and time, such as the one described here. In these architectures the weights are optimized not only to align with the target sources but also to tune away from the interfering ones, in both the spatial and the frequency domains. The obtained spatial and frequency patterns characterizing the neuronal populations pivotal to the specific decoding task can then be interpreted by fitting appropriate spatial and dynamical models.
          We first tested our solution using realistic Monte-Carlo simulations. Then, when applied to the ECoG data from Berlin BCI IV competition dataset, our architecture performed comparably to the competition winners without requiring explicit feature engineering. Moreover, using the proposed approach to the network weights interpretation we could unravel the spatial and the spectral patterns of the neuronal processes underlying the successful decoding of finger kinematics from another ECoG dataset with known sensor positions.
          As such, the proposed solution offers a good decoder and a tool for investigating neural mechanisms of motor control.},
	language = {en},
	urldate = {2020-11-16},
	institution = {Bioengineering},
	author = {Petrosuan, Arthur and Lebedev, Mikhail and Ossadtchi, Alexei},
	month = jun,
	year = {2020},
	doi = {10.1101/2020.06.02.129114},
}

@article{cecotti-convolutional-2011,
	title = {Convolutional {Neural} {Networks} for {P300} {Detection} with {Application} to {Brain}-{Computer} {Interfaces}},
	volume = {33},
	issn = {0162-8828},
	url = {http://ieeexplore.ieee.org/document/5492691/},
	doi = {10.1109/TPAMI.2010.125},
	number = {3},
	urldate = {2020-11-16},
	journal = {IEEE Transactions on Pattern Analysis and Machine Intelligence},
	author = {Cecotti, H and Graser, A},
	month = mar,
	year = {2011},
	pages = {433--445},
}

@article{schirrmeister-deep-2017,
	title = {Deep learning with convolutional neural networks for {EEG} decoding and visualization: {Convolutional} {Neural} {Networks} in {EEG} {Analysis}},
	volume = {38},
	issn = {10659471},
	shorttitle = {Deep learning with convolutional neural networks for {EEG} decoding and visualization},
	url = {http://doi.wiley.com/10.1002/hbm.23730},
	doi = {10.1002/hbm.23730},
	language = {en},
	number = {11},
	urldate = {2020-11-16},
	journal = {Human Brain Mapping},
	author = {Schirrmeister, Robin Tibor and Springenberg, Jost Tobias and Fiederer, Lukas Dominique Josef and Glasstetter, Martin and Eggensperger, Katharina and Tangermann, Michael and Hutter, Frank and Burgard, Wolfram and Ball, Tonio},
	month = nov,
	year = {2017},
	pages = {5391--5420},
}

@article{wang-ajile-2018,
	title = {{AJILE} {Movement} {Prediction}: {Multimodal} {Deep} {Learning} for {Natural} {Human} {Neural} {Recordings} and {Video}},
	shorttitle = {{AJILE} {Movement} {Prediction}},
	url = {http://arxiv.org/abs/1709.05939},
	abstract = {Developing useful interfaces between brains and machines is a grand challenge of neuroengineering. An effective interface has the capacity to not only interpret neural signals, but predict the intentions of the human to perform an action in the near future; prediction is made even more challenging outside well-controlled laboratory experiments. This paper describes our approach to detect and to predict natural human arm movements in the future, a key challenge in brain computer interfacing that has never before been attempted. We introduce the novel Annotated Joints in Long-term ECoG (AJILE) dataset; AJILE includes automatically annotated poses of 7 upper body joints for four human subjects over 670 total hours (more than 72 million frames), along with the corresponding simultaneously acquired intracranial neural recordings. The size and scope of AJILE greatly exceeds all previous datasets with movements and electrocorticography (ECoG), making it possible to take a deep learning approach to movement prediction. We propose a multimodal model that combines deep convolutional neural networks (CNN) with long short-term memory (LSTM) blocks, leveraging both ECoG and video modalities. We demonstrate that our models are able to detect movements and predict future movements up to 800 msec before movement initiation. Further, our multimodal movement prediction models exhibit resilience to simulated ablation of input neural signals. We believe a multimodal approach to natural neural decoding that takes context into account is critical in advancing bioelectronic technologies and human neuroscience.},
	urldate = {2020-11-16},
	journal = {arXiv:1709.05939 [cs, q-bio]},
	author = {Wang, Nancy Xin Ru and Farhadi, Ali and Rao, Rajesh and Brunton, Bingni},
	month = mar,
	year = {2018},
	note = {arXiv: 1709.05939},
	keywords = {Computer Science - Computer Vision and Pattern Recognition, Quantitative Biology - Neurons and Cognition},
}
